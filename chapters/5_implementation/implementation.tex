\chapter{Implementation}\label{chapter:implementation}


In this chapter, we will show how we have implemented the prototype for testing in Emerald.

\section{Testing Program}
We have developed a prototype for testing computation offloading. It is easily configurable and flexible for testing. The following two subsections will show how it is implemented.




\subsection{Computation offloading}
For computation offloading, we have used a hashing algorithm. Distributing how much each node should hash makes everything measurable and configurable. Hashing is a low memory, compute-intensive task. This is excellent for our simulation as we primarily want to focus on computational use and latency.





\subsection{Classes and Structure}
\begin{figure}[t]
    \centering
    \includegraphics[scale=0.9]{chapters/5_implementation/figures/HashWorker_class_diagram.png}
    \caption{Illustration of the class structure used for computation offloading}
    \label{fig:HashWorker_class_diagram}
\end{figure}
Figure \ref{fig:HashWorker_class_diagram} shows the class structure. We have four classes and one object. We will briefly explain each of them.


%Mention that since InternalMonitor has fields, getters and setters are automatically created at compile time, and since it is in a monitor, it is guaranteed that only one thread at a time can call those functions. 


\clearpage
\subsubsection{FileReader}
Below is the interface of class FileReader:
\begin{lstlisting}[language=emerald]
const FileReader <- class FileReader
  export op readFile[fileName: String] 
                            -> [res: Array.of[String]]
                            
  export function convertConfigToIntegers
                            [input: Array.of[String]] 
                          -> [res: Array.of[Integer]]
                            
  function stripLast[i: String] -> [o: String]
end FileReader
\end{lstlisting}
The operation \verb|readFile| will read the file with the path provided in parameter \verb|fileName|. For each line it reads, it will delete the last character with \verb|stripLast|, as it is an unwanted newline character. The function \verb|convertConfigToIntegers| is a function that converts an array of strings to an array of integers. This is needed because configs consist of lines of numbers, but they are read as strings.



\subsubsection{HashWorker}
Below is the interface of class HashWorker:
\begin{lstlisting}[language=emerald]
const HashWorker <- class HashWorker
                                [limitation: Integer]

  attached const mon <- InnerMonitor.create

  attached const InnerMonitor 
                        <- monitor class InnerMonitor

  attached const Worker
                  <- class Worker[iterations: Integer]

  initially

  export op setLimitation[lim: Integer]
  
  export op doWork[iterations: Integer, 
                    work: LocalWorkload, 
                    frequencyOfGet: integer]

  export op collectTimeUsed -> [res: Time]
end HashWorker
\end{lstlisting}
HashWorker is an object that is distributed to all machines. The role of HashWorker is to provide an interface for \verb|Main| to start and control work. The constant \verb|mon| is used to store an instance of the \verb|InnerMonitor| class. We then have the definitions for \verb|InnerMontor| and \verb|Worker|. They are defined inside the HashWorker class and are therefore inner classes.

The \verb|initially| section ensures that the class parameter \verb|limitation| is equal to or higher than zero. This is because the limitation is used to make a time constraint, and we do not want negative time.

The operation \verb|setLimitation| is there to be able to change the limitation during runtime.

The operation \verb|doWork| will create an instance of the \verb|Worker| class. It takes a parameter \verb|iterations| which is how many iterations we want the node to do, \verb|work| which is the workload that the worker will hash, and \verb|frequencyOfGet| which is how often we retrieve information from Local (the mobile device). 

The operation \verb|collectTimeUsed| is used to collect the time used after the process is done. When called, it will wait for the process in Worker to be done, then return the time used.

Notice that all of the constants are attached, as we want to ensure that they are on the same node as the HashWorker instance. This reduces the amount of costly remote reads.




\subsubsection{InternalMonitor}
Below is the whole class of InnerMontor:
\begin{lstlisting}[language=emerald]
attached const InnerMonitor 
                        <- monitor class InnerMonitor
  field waiting : Boolean <- true

  field timeTaken : Time <- nil
end InnerMonitor
\end{lstlisting}
As discussed in section \ref{emerald:fields}, fields in Emerald automatically generate getters and setters. Since it is in a monitor class, it is guaranteed that invoking them is mutually exclusive. In other words, the getters and setters that are automatically created within the class are safe to use in parallel. Variable \verb|timeTaken| is used to store the time used by the process in class \verb|Worker|. Variable \verb|waiting| is used to ensure that \verb|main| does not collect \verb|timeTaken| before the worker is done. 





\subsubsection{Worker}
Below is the outline of class Worker.

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=emerald]
attached const Worker 
                <- class Worker[iterations: Integer]
                
    initially
    
    process
    
    function djb2Hash[str: String] -> [res: Integer]
end Worker
\end{lstlisting}
\end{minipage}
The \verb|initially| section will assert that \verb|iterations| are higher than zero, because we should avoid doing a negative amount of work. The \verb|process| section is where the actual work of the node happens. When \verb|doWork| is called in class \verb|HashWorker|, it creates an instance of the Worker class by invoking operation \verb|create|. The process is then started. In the process, it will run parameter \verb|iterations| number of iterations. The hashing algorithm we use is called \textit{Djb2}. Our implementation is a converted version from a C implementation found here\cite{noauthor_hash_nodate}. 
\begin{lstlisting}[language=emerald]
function djb2Hash[str: String] -> [res: Integer]
  res <- 5381
  for i : Integer <- 0 while i < str.length 
                                    by i <- i + 1
    res <- res * 33 * str[i].ord
  end for
end djb2Hash
\end{lstlisting}
The algorithm takes a string, iterates over it, and multiplies itself with 33 and the ordinal numbers of the characters. To make it even more compute-heavy, we convert the result to string and then re-insert that into the hash function 10000 times. We see that as one iteration, as illustrated in figure \ref{fig:Hashing_algorithm_iteration}. In other words, the HashWorker will do what figure \ref{fig:Hashing_algorithm_iteration} shows, \verb|iterations| number of times. Since we throw out the result after each time, Emeralds garbage compiler will ensure that we have plenty of memory available. 
\begin{figure}[t]
    \centering
    \includegraphics[scale=0.9]{chapters/5_implementation/figures/Iteration.png}
    \caption{Illustration of one iteration in the HashWorker}
    \label{fig:Hashing_algorithm_iteration}
\end{figure}
In each iteration, it will also check if we have to get information from Local and take the time on how long we do calculations and how long we wait for a response in total.


\subsubsection{Main}
Main only has an \verb|initially| section that will do several steps. First, it will move through all nodes and print some information on each node. This is mainly for debugging and to ensure that things are running correctly. Further, it will invoke the \verb|create| method to create an instance of the \verb|FileReader| class and further read the configuration file that the user has specified. Configurations files are discussed in subsection \ref{subsection:configfiles}. Further, it will use this configuration to initialize \verb|HashWorker| instances and move them to a node decided by user input. Then, it will iterate through all \verb|HashWorker| instances and invoke operation \verb|doWork|. All processes should then have started. Finally, after all workers have finished, it will collect and print the results.



\subsection{Simulating CPU Restrictions}
To simulate CPU restrictions, we place a limitation on each HashWorker. To accurately control how much work is done on each HashWorker, we have implemented a way of specifying how many iterations (see figure \ref{fig:Hashing_algorithm_iteration}) each node can do per second.



\subsection{Configuration Files}\label{subsection:configfiles}
Main will make the \verb|FileReader| class read a specified configuration file where each line is a positive integer. For example, consider a file and two HashWorkers. Main will set the limitation of the HashWorkers to 0 and 100, and make them both do 50 iterations. Then, it will make them get from Local with a frequency of every 1 and 30 iterations respectively. Below is an example of a file that will create this set-up:
\begin{lstlisting}
0
100
1
30
50
50

\end{lstlisting}

The \verb|FileReader| reads each line until the newline character. The configuration file is terminated by an emtpy line at the end. After everything is read, it will convert them to an array of integers, instead of array of strings. 

\subsection{Placing HashWorkers}
Placement of HashWorkers is prompted in the terminal. When testing, you will get information about a HashWorker, and a choice for which node you want to place it on. 














% -----------------------------------------------------------------------------------

\section{Multi-Access Edge Computing}

\begin{figure}[t]
    \centering
    \includegraphics[scale=1]{chapters/5_implementation/figures/MEC_implementation.png}
    \caption{Illustration of example node structure used for computation offloading in MEC}
    \label{fig:MEC_implementation}
\end{figure}
Figure \ref{fig:MEC_implementation} illustrates how three nodes can be set up. The \verb|Main| object will reside on the mobile device, as we want the result there. We can create several HashWorkers to place them on servers. However, the Cloud Data Center will have enough resources to have significantly more HashWorkers than the MEC Servers, and the MEC Servers can have significantly more HashWorkers than the mobile client. The MEC Servers can consist of one or more machines that host one-to-many HashWorker instances. The Cloud Data Center consists of many machines that can host one-to-many HashWorker instances.




% -------------------------------------------------------------------

\section{Cloudlets}
\begin{figure}[t]
    \centering
    \includegraphics[scale=0.9]{chapters/5_implementation/figures/Cloudlet_implementation.png}
    \caption{Illustration of example node structure used for computation offloading with Cloudlets}
    \label{fig:Cloudlet_implementation}
\end{figure}
Figure \ref{fig:Cloudlet_implementation} illustrates how we can set up an example implementation of Cloudlets. The mobile device will be in very short distance of the Cloudlets and therefore use WiFi to connect with them.






\section{Source Code}
Source code for the implementation and configuration files can be found in the following git repository that is being cited\cite{johnsen_daniejohmasterprograms_nodate}.






\section{Summary}
In this chapter, we have described the prototype we have created. The prototype can be set up with configuration files to control different parameters for each worker on each node. This allows us quickly set up high-level simulations of Near-Far architectures and models. Additionally, we have provided some examples of how it can be used to model Cloudlets and Multi-Access Edge Computing.